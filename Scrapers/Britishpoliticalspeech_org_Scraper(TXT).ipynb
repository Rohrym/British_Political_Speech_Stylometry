{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439d3df4",
   "metadata": {},
   "source": [
    "# Basic Britishpoliticalspeech.org Scraper (TXT)\n",
    "\n",
    "This python based scraper will scrape British political speeches from political leaders in the UK from [Britishpoliticalspeech.org](http://britishpoliticalspeech.org/). When fully run the scraper will output a directory with txt files of all the individual speeches held. These could be used for specific textual analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5292d9d0-5c94-412c-b0ce-aaffaf0b1c92",
   "metadata": {
    "id": "5292d9d0-5c94-412c-b0ce-aaffaf0b1c92"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86543cd3-8e52-468b-972b-2f0feb173afc",
   "metadata": {
    "id": "86543cd3-8e52-468b-972b-2f0feb173afc"
   },
   "outputs": [],
   "source": [
    "# This function loads a webpage\n",
    "def load_page(url):\n",
    "    with requests.get(url) as f:\n",
    "        page = f.text\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91d3ca-5820-4553-b49e-cb3a548b20ee",
   "metadata": {
    "id": "9e91d3ca-5820-4553-b49e-cb3a548b20ee"
   },
   "source": [
    "## Locate the speeches\n",
    "Here we define two functions to first extract the hyperlinks from the speeches from the main content table of the archive using `get_speech_data()`, and secondly to download the speech texts on the specific speech pages linked in the content table using the `get_speech()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117749c4-9370-417d-8c4b-f48d105f784d",
   "metadata": {
    "id": "117749c4-9370-417d-8c4b-f48d105f784d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_speech_data(url):\n",
    "    speech_page = BeautifulSoup(load_page(url), 'lxml')  # Open the webpage \n",
    "    if not speech_page:                                            \n",
    "        print('Something went wrong!', file=sys.stderr)\n",
    "        sys.exit()\n",
    "    data = []\n",
    "    for row in speech_page.find_all('tr')[2:]:\n",
    "        speech = row.find_all('td')[3] #Find the name of the every speech\n",
    "        link = row.find('a').get('href') #Find the hyperlink for every speech\n",
    "        data.append({\n",
    "            'link': 'http://britishpoliticalspeech.org/' + link\n",
    "        }) #Store the hyperlinks in 'data'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f936da2",
   "metadata": {
    "id": "9f936da2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_speech(url):\n",
    "    speech_page = BeautifulSoup(load_page(url), 'lxml')    #Open the speech webpage\n",
    "    interesting_html = (speech_page.find(class_='speech-content').text.strip()\n",
    "        .replace('\\xa0\\n', '').replace('\\n','').replace('\\x85','').replace('\\u2011','')) #Find the full text of the speech\n",
    "    skip_check = 'Owing to a copyright issue this speech has been removed.' #Check of this text is in the speech, otherwise this can be skipped\n",
    "    if not interesting_html or skip_check in interesting_html: # or not speaker_html or not location_html don't really care about not finding these\n",
    "        #print('Skipped - No information available for {}'.format(url), file=sys.stderr)\n",
    "        return {}\n",
    "    return {'speech' : interesting_html} #returns the full text of the speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58deb644",
   "metadata": {},
   "source": [
    "## Scraping the Data\n",
    "\n",
    "The following code will proceed to apply the previously made functions for scraping the desired data and writes the output in txt files in a newly created directory called \"speeches\". This directory will be in the created wherever you stored this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb4d759",
   "metadata": {
    "id": "cfb4d759",
    "outputId": "95a5dc13-ffc0-473a-f5d7-c37d2adfe619",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scraping!\n"
     ]
    }
   ],
   "source": [
    "index_url = 'http://britishpoliticalspeech.org/speech-archive.htm'         # Contains a list of speeches\n",
    "list_speech_data = get_speech_data(index_url)                      # Get speeches with metadata\n",
    "list_rows_to_remove = []\n",
    "#print (\" - - - - - \" + str(len(list_speech_data)))\n",
    "\n",
    "for count, row in enumerate(list_speech_data):\n",
    "    #print('Scraping info on {}.'.format(row['name speech'])) # Might be useful for debugging\n",
    "    url = row['link']\n",
    "    speech_info = get_speech(url)                    # Get the speech, if available\n",
    "    if speech_info == {}:\n",
    "        list_rows_to_remove.append(count)\n",
    "    else:    \n",
    "        for key, value in speech_info.items():\n",
    "            row[key] = value                              # Add the new data to our dictionary\n",
    "    #print('Scraped info on {}.'.format(row['name speech']) + '\\t from {}.'.format(row['speakers']))\n",
    "\n",
    "for d_elem in reversed(list_rows_to_remove): # Delete list rows in reverse to avoid errors\n",
    "    #print(\"Speech missing - Deleted: \" + str(d_elem))\n",
    "    del list_speech_data[d_elem]\n",
    "\n",
    "#print (\" - - - - - \" + str(len(list_speech_data)))\n",
    "print('Done scraping!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c73e775",
   "metadata": {
    "id": "8c73e775",
    "outputId": "1fb24862-e638-4375-dd90-e19e498a55dd"
   },
   "outputs": [],
   "source": [
    "path = \"speeches/\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "\n",
    "if not isExist:  \n",
    "    # Create a new directory because it does not exist \n",
    "    os.makedirs(path)\n",
    "    print(\"The new directory is created!\")\n",
    "\n",
    "# Write the speeches in txt files with the id as file name\n",
    "number = 1\n",
    "for row in list_speech_data:\n",
    "    filename = f'political_speech_{number}.txt'\n",
    "    #filename = row['id']\n",
    "    #print(filename)\n",
    "    file1 = open(path + filename,\"w\")\n",
    "    number += 1\n",
    "    file1.writelines(row['speech'])\n",
    "    file1.close() #to change file access modes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ef30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BritishPoliticalspeech1.org.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
