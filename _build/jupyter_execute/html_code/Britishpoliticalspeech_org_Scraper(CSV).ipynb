{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c56034",
   "metadata": {},
   "source": [
    "# Basic Britishpoliticalspeech.org Scraper (CSV)\n",
    "\n",
    "This python based scraper will scrape British political speeches from political leaders in the UK from Britishpoliticalspeech.org. When fully run the scraper will output a CSV file containing basic metadata about the speeches and the speeches themselves. These could for further analysis with for instance tools from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5292d9d0-5c94-412c-b0ce-aaffaf0b1c92",
   "metadata": {
    "id": "5292d9d0-5c94-412c-b0ce-aaffaf0b1c92"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86543cd3-8e52-468b-972b-2f0feb173afc",
   "metadata": {
    "id": "86543cd3-8e52-468b-972b-2f0feb173afc"
   },
   "outputs": [],
   "source": [
    "def load_page(url):\n",
    "    with requests.get(url) as f:\n",
    "        page = f.text\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91d3ca-5820-4553-b49e-cb3a548b20ee",
   "metadata": {
    "id": "9e91d3ca-5820-4553-b49e-cb3a548b20ee"
   },
   "source": [
    "## Locate the Data\n",
    "\n",
    "The MetaData is inside of the < tbody > tag. Each row is either inside a < tr class=\"odd\" > tag or in a < tr > tag. Every attribute (Date, Party, Speaker, Title) is in a < td > tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117749c4-9370-417d-8c4b-f48d105f784d",
   "metadata": {
    "id": "117749c4-9370-417d-8c4b-f48d105f784d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_speech_data(url):\n",
    "    speech_page = BeautifulSoup(load_page(url), 'lxml')       \n",
    "    if not speech_page:                                            \n",
    "        print('Something went wrong!', file=sys.stderr)\n",
    "        sys.exit()\n",
    "    data = []\n",
    "    for count, row in enumerate(speech_page.find_all('tr')[2:]):\n",
    "    #for row in speech_page.find_all('tr')[2:]:\n",
    "        dates = row.find_all('td')[0]\n",
    "        parties = row.find_all('td')[1]\n",
    "        speakers = row.find_all('td')[2]\n",
    "        speech = row.find_all('td')[3]\n",
    "        link = row.find('a').get('href')\n",
    "        data.append({\n",
    "            'id' : parties.text + '_' + str(count),\n",
    "            'date': dates.text,\n",
    "            'speaker': speakers.text,\n",
    "            'party': parties.text,\n",
    "            'name speech': speech.text,\n",
    "            'link': 'http://britishpoliticalspeech.org/' + link\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f936da2",
   "metadata": {
    "id": "9f936da2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_speech(url):\n",
    "    speech_page = BeautifulSoup(load_page(url), 'lxml')                  \n",
    "    interesting_html = (speech_page.find(class_='speech-content').text.strip()\n",
    "        .replace('\\xa0\\n', '').replace('\\n','').replace('\\x85','').replace('\\u2011',''))\n",
    "    skip_check = 'Owing to a copyright issue this speech has been removed.'\n",
    "    speaker_html = speech_page.find(class_='speech-speaker').text.strip().split('(', 1)[0]\n",
    "    location_html = speech_page.find(class_='speech-location').text.strip()\n",
    "    if 'Location: ' in location_html:\n",
    "        location_html = location_html.replace('Location: ', '')\n",
    "    if not interesting_html or skip_check in interesting_html: # or not speaker_html or not location_html don't really care about not finding these\n",
    "        #print('Skipped - No information available for {}'.format(url), file=sys.stderr)\n",
    "        return {}                                                      \n",
    "    return {'speech' : interesting_html, 'speaker' : speaker_html, 'location' : location_html}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808d692",
   "metadata": {},
   "source": [
    "## Scraping the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb4d759",
   "metadata": {
    "id": "cfb4d759",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index_url = 'http://britishpoliticalspeech.org/speech-archive.htm'         # Contains a list of speeches\n",
    "list_speech_data = get_speech_data(index_url)                      # Get speeches with metadata\n",
    "list_rows_to_remove = []\n",
    "#print (\" - - - - - \" + str(len(list_speech_data)))\n",
    "\n",
    "for count, row in enumerate(list_speech_data):\n",
    "    #print('Scraping info on {}.'.format(row['name speech'])) # Might be useful for debugging\n",
    "    url = row['link']\n",
    "    speech_info = get_speech(url)                    # Get the speech, if available\n",
    "    if speech_info == {}:\n",
    "        list_rows_to_remove.append(count)\n",
    "    else:    \n",
    "        for key, value in speech_info.items():\n",
    "            row[key] = value                              # Add the new data to our dictionary\n",
    "    #print('Scraped info on {}.'.format(row['name speech']) + '\\t from {}.'.format(row['speakers']))\n",
    "\n",
    "for d_elem in reversed(list_rows_to_remove): # Delete list rows in reverse to avoid errors\n",
    "    #print(\"Speech missing - Deleted: \" + str(d_elem))\n",
    "    del list_speech_data[d_elem]\n",
    "\n",
    "#print (\" - - - - - \" + str(len(list_speech_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c73e775",
   "metadata": {
    "id": "8c73e775"
   },
   "outputs": [],
   "source": [
    "with open('speech_metadata.csv', 'w', encoding='utf-8') as f:       # Open a csv file for writing\n",
    "    fieldnames=['id','speaker', 'party', 'location', 'date', 'name speech',\n",
    "                'speech']                                 # These are the values we want to store\n",
    "    writer = csv.DictWriter(f,\n",
    "                            delimiter=',',                # Common delimiter\n",
    "                            quotechar='\"',                # Common quote character\n",
    "                            quoting=csv.QUOTE_NONNUMERIC, # Make sure that all strings are quoted\n",
    "                            fieldnames=fieldnames\n",
    "                            )\n",
    "    writer.writeheader()                                  # Create headers in our csv file\n",
    "    for row in list_speech_data:\n",
    "        writer.writerow({k:v for k,v in row.items() if k in fieldnames})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "UpatVBritishpoliticalspeech.org Scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}